{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a11124ab-4838-4351-bd0f-346ab38fde29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Layer, LSTM, Dense, Flatten, Dropout, Conv1D, InputLayer, BatchNormalization, SimpleRNN\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ababe2a7-719d-4847-9677-9b6aa92bb52a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 1: Generate Training Data\n",
    "def generate_strings(num_samples):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        # Generate strings that belong to the grammar {0+,1}\n",
    "        string_length = np.random.randint(1, 61)  # Random string length up to 60 characters\n",
    "        string = ['0' if np.random.rand() < 0.9 else '1' for _ in range(string_length)]\n",
    "        \n",
    "        # Pad or truncate the string to ensure it has a fixed length (e.g., 60)\n",
    "        if len(string) < 60:\n",
    "            string += ['0'] * (60 - len(string))\n",
    "        elif len(string) > 60:\n",
    "            string = string[:60]\n",
    "        \n",
    "        # # Pad the string to a length of 80\n",
    "        string += ['0'] * (80 - len(string))\n",
    "        \n",
    "        data.append(''.join(string))\n",
    "        labels.append('1')  # 1 for strings that belong to the grammar\n",
    "\n",
    "        # Generate counterexamples (strings that do not belong to the grammar)\n",
    "        string_length = np.random.randint(1, 61)  # Random string length up to 60 characters\n",
    "        string = ['1' if np.random.rand() < 0.9 else '0' for _ in range(string_length)]\n",
    "        \n",
    "        # Pad or truncate the string to ensure it has a fixed length (e.g., 60)\n",
    "        if len(string) < 60:\n",
    "            string += ['0'] * (60 - len(string))\n",
    "        elif len(string) > 60:\n",
    "            string = string[:60]\n",
    "        \n",
    "        # # Pad the string to a length of 80\n",
    "        string += ['0'] * (80 - len(string))\n",
    "        \n",
    "        data.append(''.join(string))\n",
    "        labels.append('0')  # 0 for counterexamples\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c96123b8-d079-4182-9dbd-17d500e4eaba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples = 500\n",
    "data, labels = generate_strings(num_samples)\n",
    "len(data), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77d58641-114d-45af-8520-64921e3c64d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a function to one-hot encode a string\n",
    "def one_hot_encode(string, num_classes):\n",
    "    return tf.keras.utils.to_categorical([int(c) for c in string], num_classes=num_classes)\n",
    "\n",
    "num_classes = 2  # 0 or 1\n",
    "\n",
    "# One-hot encode the strings\n",
    "encoded_data = np.array([one_hot_encode(s, num_classes) for s in data])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(encoded_data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ensure that labels are integers (0 or 1) and convert them to NumPy arrays\n",
    "y_train = np.array([int(label) for label in y_train])\n",
    "y_val = np.array([int(label) for label in y_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ff8e03a-558b-438a-96ff-13d83000a75e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 61, 1)             41        \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 61)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 62        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 103\n",
      "Trainable params: 103\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_tdnn():\n",
    "    num_classes = 2\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(80, num_classes)))\n",
    "    model.add(Conv1D(1, 20, activation='relu'))\n",
    "    # model.add(Conv1D(64, 20, activation='relu'))\n",
    "    # model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    # model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    # model.add(Dropout(best_dropout_rate))  # Adding dropout layer to reduce overfitting\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model_tdnn = build_tdnn()\n",
    "model_tdnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "636e87a2-6f90-44c4-b9d6-958c32c37db8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 4)                 28        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                100       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 149\n",
      "Trainable params: 149\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_rnn():\n",
    "    num_classes = 2\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(80, num_classes)))\n",
    "    model.add(SimpleRNN(4, return_sequences=False, unroll=True))\n",
    "    # model.add(SimpleRNN(128, activation='relu', return_sequences=True))\n",
    "    # model.add(SimpleRNN(64, activation='relu', return_sequences=True))\n",
    "    # model.add(SimpleRNN(64))\n",
    "    # model.add(LSTM(128, activation='relu', return_sequences=True))\n",
    "    # model.add(LSTM(64, activation='relu'))\n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model_rnn = build_rnn()\n",
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65c195c9-b7ef-47c7-a19d-c31dab704a2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TDNN Evaluation\n",
      "Epoch 1/25\n",
      "25/25 [==============================] - 5s 22ms/step - loss: 0.8162 - accuracy: 0.5000 - val_loss: 0.7375 - val_accuracy: 0.5300\n",
      "Epoch 2/25\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.7134 - accuracy: 0.5175 - val_loss: 0.6969 - val_accuracy: 0.5650\n",
      "Epoch 3/25\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.6914 - accuracy: 0.5163 - val_loss: 0.6752 - val_accuracy: 0.5000\n",
      "Epoch 4/25\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.6650 - accuracy: 0.5487 - val_loss: 0.6357 - val_accuracy: 0.6100\n",
      "Epoch 5/25\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.6121 - accuracy: 0.6050 - val_loss: 0.5563 - val_accuracy: 0.6600\n",
      "Epoch 6/25\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.5381 - accuracy: 0.6737 - val_loss: 0.4839 - val_accuracy: 0.7700\n",
      "Epoch 7/25\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.4862 - accuracy: 0.7625 - val_loss: 0.4464 - val_accuracy: 0.8250\n",
      "Epoch 8/25\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.4587 - accuracy: 0.8000 - val_loss: 0.4245 - val_accuracy: 0.8800\n",
      "Epoch 9/25\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.4402 - accuracy: 0.8475 - val_loss: 0.4092 - val_accuracy: 0.8900\n",
      "Epoch 10/25\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.4266 - accuracy: 0.8687 - val_loss: 0.3971 - val_accuracy: 0.9000\n",
      "Epoch 11/25\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.4153 - accuracy: 0.8788 - val_loss: 0.3872 - val_accuracy: 0.9050\n",
      "Epoch 12/25\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.4057 - accuracy: 0.8938 - val_loss: 0.3784 - val_accuracy: 0.9250\n",
      "Epoch 13/25\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3972 - accuracy: 0.8975 - val_loss: 0.3707 - val_accuracy: 0.9250\n",
      "Epoch 14/25\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.3896 - accuracy: 0.9013 - val_loss: 0.3637 - val_accuracy: 0.9300\n",
      "Epoch 15/25\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.3826 - accuracy: 0.9038 - val_loss: 0.3572 - val_accuracy: 0.9300\n",
      "Epoch 16/25\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.3759 - accuracy: 0.9050 - val_loss: 0.3509 - val_accuracy: 0.9300\n",
      "Epoch 17/25\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3695 - accuracy: 0.9100 - val_loss: 0.3450 - val_accuracy: 0.9300\n",
      "Epoch 18/25\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3633 - accuracy: 0.9137 - val_loss: 0.3395 - val_accuracy: 0.9300\n",
      "Epoch 19/25\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.3576 - accuracy: 0.9175 - val_loss: 0.3342 - val_accuracy: 0.9300\n",
      "Epoch 20/25\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.3517 - accuracy: 0.9162 - val_loss: 0.3291 - val_accuracy: 0.9250\n",
      "Epoch 21/25\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.3461 - accuracy: 0.9162 - val_loss: 0.3242 - val_accuracy: 0.9250\n",
      "Epoch 22/25\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3407 - accuracy: 0.9187 - val_loss: 0.3195 - val_accuracy: 0.9250\n",
      "Epoch 23/25\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3354 - accuracy: 0.9187 - val_loss: 0.3151 - val_accuracy: 0.9250\n",
      "Epoch 24/25\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3304 - accuracy: 0.9200 - val_loss: 0.3107 - val_accuracy: 0.9250\n",
      "Epoch 25/25\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.3255 - accuracy: 0.9262 - val_loss: 0.3068 - val_accuracy: 0.9300\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3068 - accuracy: 0.9300\n",
      "\n",
      "RNN Evaluation\n",
      "Epoch 1/30\n",
      "17/17 [==============================] - 7s 130ms/step - loss: 0.6936 - accuracy: 0.5038 - val_loss: 0.6940 - val_accuracy: 0.4850\n",
      "Epoch 2/30\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6933 - accuracy: 0.5038 - val_loss: 0.6933 - val_accuracy: 0.4850\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 1s 38ms/step - loss: 0.6932 - accuracy: 0.5038 - val_loss: 0.6933 - val_accuracy: 0.4850\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6932 - accuracy: 0.5038 - val_loss: 0.6936 - val_accuracy: 0.4850\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6933 - accuracy: 0.5038 - val_loss: 0.6935 - val_accuracy: 0.4850\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6932 - accuracy: 0.5038 - val_loss: 0.6934 - val_accuracy: 0.4850\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6936 - accuracy: 0.5038 - val_loss: 0.6936 - val_accuracy: 0.4850\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6936 - accuracy: 0.4563 - val_loss: 0.6933 - val_accuracy: 0.4850\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 1s 38ms/step - loss: 0.6932 - accuracy: 0.4837 - val_loss: 0.6932 - val_accuracy: 0.4850\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6934 - accuracy: 0.5038 - val_loss: 0.6935 - val_accuracy: 0.4850\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 1s 37ms/step - loss: 0.6932 - accuracy: 0.5038 - val_loss: 0.6933 - val_accuracy: 0.4850\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 1s 38ms/step - loss: 0.6933 - accuracy: 0.4812 - val_loss: 0.6931 - val_accuracy: 0.5150\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6933 - accuracy: 0.5038 - val_loss: 0.6935 - val_accuracy: 0.4850\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6936 - accuracy: 0.4688 - val_loss: 0.6932 - val_accuracy: 0.4850\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 1s 38ms/step - loss: 0.6931 - accuracy: 0.5038 - val_loss: 0.6935 - val_accuracy: 0.4850\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6932 - accuracy: 0.5038 - val_loss: 0.6938 - val_accuracy: 0.4850\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 1s 37ms/step - loss: 0.6934 - accuracy: 0.5038 - val_loss: 0.6939 - val_accuracy: 0.4850\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6932 - accuracy: 0.5038 - val_loss: 0.6934 - val_accuracy: 0.4850\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 1s 38ms/step - loss: 0.6933 - accuracy: 0.5038 - val_loss: 0.6933 - val_accuracy: 0.4850\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6932 - accuracy: 0.5038 - val_loss: 0.6932 - val_accuracy: 0.4850\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6933 - accuracy: 0.5038 - val_loss: 0.6934 - val_accuracy: 0.4850\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6933 - accuracy: 0.5038 - val_loss: 0.6933 - val_accuracy: 0.4850\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6936 - accuracy: 0.4712 - val_loss: 0.6931 - val_accuracy: 0.5150\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 1s 37ms/step - loss: 0.6932 - accuracy: 0.5088 - val_loss: 0.6937 - val_accuracy: 0.4850\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6933 - accuracy: 0.5038 - val_loss: 0.6934 - val_accuracy: 0.4850\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6934 - accuracy: 0.5038 - val_loss: 0.6940 - val_accuracy: 0.4850\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6933 - accuracy: 0.5038 - val_loss: 0.6933 - val_accuracy: 0.4850\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6933 - accuracy: 0.5038 - val_loss: 0.6935 - val_accuracy: 0.4850\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 1s 38ms/step - loss: 0.6932 - accuracy: 0.5038 - val_loss: 0.6934 - val_accuracy: 0.4850\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6934 - accuracy: 0.5038 - val_loss: 0.6937 - val_accuracy: 0.4850\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.6937 - accuracy: 0.4850\n",
      "\n",
      "TDNN - Val Loss: 0.30680087208747864, Val Accuracy: 0.9300000071525574\n",
      "RNN - Val Loss: 0.6936829090118408, Val Accuracy: 0.48500001430511475\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train and evaluate the models\n",
    "print(\"TDNN Evaluation\")\n",
    "# model_tdnn.fit(x_train, y_train, epochs=10, batch_size=32)\n",
    "# model_tdnn.fit(x_train, y_train, epochs=25, batch_size=32, validation_data=(x_val, y_val), callbacks=[early_stopping])\n",
    "model_tdnn.fit(x_train, y_train, epochs=25, batch_size=32, validation_data=(x_val, y_val))\n",
    "tdnn_loss, tdnn_accuracy = model_tdnn.evaluate(x_val, y_val)\n",
    "print(\"\\nRNN Evaluation\")\n",
    "# model_rnn.fit(x_train, y_train, epochs=30, batch_size=32, validation_data=(x_val, y_val), callbacks=[early_stopping])\n",
    "# model_rnn.fit(x_train, y_train, epochs=30, batch_size=16, validation_data=(x_val, y_val), callbacks=[early_stopping])\n",
    "model_rnn.fit(x_train, y_train, epochs=30, batch_size=48, validation_data=(x_val, y_val))\n",
    "rnn_loss, rnn_accuracy = model_rnn.evaluate(x_val, y_val)\n",
    "\n",
    "print(f\"\\nTDNN - Val Loss: {tdnn_loss}, Val Accuracy: {tdnn_accuracy}\")\n",
    "print(f\"RNN - Val Loss: {rnn_loss}, Val Accuracy: {rnn_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb3c5c3-fa8f-424f-9a25-8aa07237df9a",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "347e40d7-4af0-4b44-b1d5-4f8275f72ad8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the data from the text file\n",
    "data = np.loadtxt('test.txt', dtype=str)\n",
    "# print(\"Before:\", data)\n",
    "\n",
    "new_data = []\n",
    "labels = []\n",
    "for line in data:\n",
    "    line = line.replace(\",\", \"\")  # Remove commas\n",
    "    data = line[:-1] # Drop the last element in each line\n",
    "    label = line[-1] # Last element is class label\n",
    "    new_data.append(data)\n",
    "    labels.append(label)\n",
    "\n",
    "# print(len(new_data))\n",
    "# print(len(labels[0]))\n",
    "# type(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "427e2df3-aeef-466a-aeda-d85d24c88838",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a function to one-hot encode a string\n",
    "def one_hot_encode(string, num_classes):\n",
    "    return tf.keras.utils.to_categorical([int(c) for c in string], num_classes=num_classes)\n",
    "\n",
    "num_classes = 2  # 0 or 1\n",
    "\n",
    "# One-hot encode the strings\n",
    "encoded_new_data = np.array([one_hot_encode(s, num_classes) for s in new_data])\n",
    "# encoded_new_data = encoded_new_data.reshape(-1, 60, 2)\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(encoded_new_data, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d22a9400-a905-45b9-b03a-3795c05eebb2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3660 - accuracy: 0.9240\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.6878 - accuracy: 0.7280\n",
      "With Evaluate Method\n",
      "---------------------------------------------------------------\n",
      "TDNN - Test Loss: 0.3660324215888977, Test Accuracy: 0.9240000247955322\n",
      "RNN - Test Loss: 0.6877744793891907, Test Accuracy: 0.7279999852180481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # TDNN Model\n",
    "# tdnn_model = Sequential([\n",
    "#     InputLayer(input_shape=(80, num_classes)),  # Input layer for one-hot encoded strings\n",
    "#     Conv1D(64, 5, activation='relu'),  # 5 is the delay line size\n",
    "#     Flatten(),\n",
    "#     Dense(128, activation='relu'),  # Vary the number of neurons as needed\n",
    "#     Dense(1, activation='sigmoid')  # Output layer with one neuron for binary classification\n",
    "# ])\n",
    "\n",
    "# # Compile the TDNN model\n",
    "# tdnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # RNN Model\n",
    "# rnn_model = Sequential([\n",
    "#     InputLayer(input_shape=(80, num_classes)),  # Input layer for one-hot encoded strings\n",
    "#     SimpleRNN(64),  # Vary the number of neurons as needed\n",
    "#     Dense(1, activation='sigmoid')  # Output layer with one neuron for binary classification\n",
    "# ])\n",
    "\n",
    "# # Compile the RNN model\n",
    "# rnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Ensure that labels are integers (0 or 1) and convert them to NumPy arrays\n",
    "y_test = np.array([int(label) for label in labels])\n",
    "# y_test = np.array([int(label) for label in y_test])\n",
    "\n",
    "# # Train the models\n",
    "# model_tdnn.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "# model_rnn.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluate the models on the test data\n",
    "tdnn_loss, tdnn_accuracy = model_tdnn.evaluate(encoded_new_data, y_test)\n",
    "rnn_loss, rnn_accuracy = model_rnn.evaluate(encoded_new_data, y_test)\n",
    "\n",
    "# # Train the models\n",
    "# tdnn_model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "# rnn_model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# # Evaluate the models on the test data\n",
    "# tdnn_loss, tdnn_accuracy = tdnn_model.evaluate(X_test, y_test)\n",
    "# rnn_loss, rnn_accuracy = rnn_model.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"With Evaluate Method\")\n",
    "print(\"---------------------------------------------------------------\")\n",
    "print(f\"TDNN - Test Loss: {tdnn_loss}, Test Accuracy: {tdnn_accuracy}\")\n",
    "print(f\"RNN - Test Loss: {rnn_loss}, Test Accuracy: {rnn_accuracy}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7aff066-673b-4cd2-8ae5-dfd43c19720a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step\n",
      "16/16 [==============================] - 2s 15ms/step\n",
      "TDNN Accuracy: 0.924\n",
      "RNN Accuracy: 0.728\n",
      "TDNN Confusion Matrix:\n",
      "[[223  27]\n",
      " [ 11 239]]\n",
      "\n",
      "RNN Confusion Matrix:\n",
      "[[119 131]\n",
      " [  5 245]]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "tdnn_predictions = model_tdnn.predict(encoded_new_data)\n",
    "rnn_predictions = model_rnn.predict(encoded_new_data)\n",
    "\n",
    "# Convert model outputs to binary predictions\n",
    "threshold = 0.5  # Adjust the threshold as needed\n",
    "tdnn_binary_predictions = (tdnn_predictions > threshold).astype(int)\n",
    "rnn_binary_predictions = (rnn_predictions > threshold).astype(int)\n",
    "\n",
    "# Calculate confusion matrices\n",
    "tdnn_confusion_matrix = confusion_matrix(y_test, tdnn_binary_predictions)\n",
    "rnn_confusion_matrix = confusion_matrix(y_test, rnn_binary_predictions)\n",
    "\n",
    "print(\"TDNN Accuracy:\", accuracy_score(y_test, tdnn_binary_predictions))\n",
    "print(\"RNN Accuracy:\", accuracy_score(y_test, rnn_binary_predictions))\n",
    "# Display the confusion matrices\n",
    "print(\"TDNN Confusion Matrix:\")\n",
    "print(tdnn_confusion_matrix)\n",
    "\n",
    "print(\"\\nRNN Confusion Matrix:\")\n",
    "print(rnn_confusion_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
