{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a11124ab-4838-4351-bd0f-346ab38fde29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Layer, LSTM, Dense, Flatten, Dropout, Conv1D, InputLayer, BatchNormalization, SimpleRNN\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ababe2a7-719d-4847-9677-9b6aa92bb52a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 1: Generate Training Data\n",
    "def generate_strings(num_samples):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        # Generate strings that belong to the grammar {0+,1}\n",
    "        string_length = np.random.randint(1, 61)  # Random string length up to 60 characters\n",
    "        string = ['0' if np.random.rand() < 0.9 else '1' for _ in range(string_length)]\n",
    "        \n",
    "        # Pad or truncate the string to ensure it has a fixed length (e.g., 60)\n",
    "        if len(string) < 60:\n",
    "            string += ['0'] * (60 - len(string))\n",
    "        elif len(string) > 60:\n",
    "            string = string[:60]\n",
    "        \n",
    "        # Pad the string to a length of 80\n",
    "        string += ['0'] * (80 - len(string))\n",
    "        \n",
    "        data.append(''.join(string))\n",
    "        labels.append('1')  # 1 for strings that belong to the grammar\n",
    "\n",
    "        # Generate counterexamples (strings that do not belong to the grammar)\n",
    "        string_length = np.random.randint(1, 61)  # Random string length up to 60 characters\n",
    "        string = ['1' if np.random.rand() < 0.9 else '0' for _ in range(string_length)]\n",
    "        \n",
    "        # Pad or truncate the string to ensure it has a fixed length (e.g., 60)\n",
    "        if len(string) < 60:\n",
    "            string += ['0'] * (60 - len(string))\n",
    "        elif len(string) > 60:\n",
    "            string = string[:60]\n",
    "        \n",
    "        # Pad the string to a length of 80\n",
    "        string += ['0'] * (80 - len(string))\n",
    "        \n",
    "        data.append(''.join(string))\n",
    "        labels.append('0')  # 0 for counterexamples\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c96123b8-d079-4182-9dbd-17d500e4eaba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples = 500\n",
    "data, labels = generate_strings(num_samples)\n",
    "len(data), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77d58641-114d-45af-8520-64921e3c64d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a function to one-hot encode a string\n",
    "def one_hot_encode(string, num_classes):\n",
    "    return tf.keras.utils.to_categorical([int(c) for c in string], num_classes=num_classes)\n",
    "\n",
    "num_classes = 2  # 0 or 1\n",
    "\n",
    "# One-hot encode the strings\n",
    "encoded_data = np.array([one_hot_encode(s, num_classes) for s in data])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(encoded_data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ensure that labels are integers (0 or 1) and convert them to NumPy arrays\n",
    "y_train = np.array([int(label) for label in y_train])\n",
    "y_val = np.array([int(label) for label in y_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ff8e03a-558b-438a-96ff-13d83000a75e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 76, 1)             11        \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 76)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 77        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 88\n",
      "Trainable params: 88\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_tdnn():\n",
    "    num_classes = 2\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(80, num_classes)))\n",
    "    model.add(Conv1D(1, 5, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model_tdnn = build_tdnn()\n",
    "model_tdnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "636e87a2-6f90-44c4-b9d6-958c32c37db8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 4)                 28        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                100       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 149\n",
      "Trainable params: 149\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_rnn():\n",
    "    num_classes = 2\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(80, num_classes)))\n",
    "    model.add(SimpleRNN(4, return_sequences=False, unroll=True))\n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model_rnn = build_rnn()\n",
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65c195c9-b7ef-47c7-a19d-c31dab704a2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TDNN Evaluation\n",
      "Epoch 1/25\n",
      "25/25 [==============================] - 3s 16ms/step - loss: 0.7054 - accuracy: 0.5163 - val_loss: 0.6992 - val_accuracy: 0.5150\n",
      "Epoch 2/25\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6974 - accuracy: 0.5362 - val_loss: 0.6923 - val_accuracy: 0.5450\n",
      "Epoch 3/25\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.6921 - accuracy: 0.5562 - val_loss: 0.6873 - val_accuracy: 0.5650\n",
      "Epoch 4/25\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.6876 - accuracy: 0.5612 - val_loss: 0.6818 - val_accuracy: 0.5850\n",
      "Epoch 5/25\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.6820 - accuracy: 0.5675 - val_loss: 0.6744 - val_accuracy: 0.6250\n",
      "Epoch 6/25\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.6742 - accuracy: 0.5838 - val_loss: 0.6635 - val_accuracy: 0.6250\n",
      "Epoch 7/25\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.6626 - accuracy: 0.5975 - val_loss: 0.6437 - val_accuracy: 0.6450\n",
      "Epoch 8/25\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.5949 - accuracy: 0.6500 - val_loss: 0.5286 - val_accuracy: 0.7050\n",
      "Epoch 9/25\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.4949 - accuracy: 0.6687 - val_loss: 0.4567 - val_accuracy: 0.7100\n",
      "Epoch 10/25\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.4449 - accuracy: 0.7138 - val_loss: 0.4198 - val_accuracy: 0.8200\n",
      "Epoch 11/25\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.4119 - accuracy: 0.8213 - val_loss: 0.3915 - val_accuracy: 0.9050\n",
      "Epoch 12/25\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 0.3852 - accuracy: 0.9000 - val_loss: 0.3696 - val_accuracy: 0.9450\n",
      "Epoch 13/25\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 0.3682 - accuracy: 0.9312 - val_loss: 0.3556 - val_accuracy: 0.9550\n",
      "Epoch 14/25\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.3563 - accuracy: 0.9388 - val_loss: 0.3443 - val_accuracy: 0.9550\n",
      "Epoch 15/25\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.3463 - accuracy: 0.9463 - val_loss: 0.3347 - val_accuracy: 0.9550\n",
      "Epoch 16/25\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.3375 - accuracy: 0.9525 - val_loss: 0.3261 - val_accuracy: 0.9550\n",
      "Epoch 17/25\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.3293 - accuracy: 0.9550 - val_loss: 0.3181 - val_accuracy: 0.9600\n",
      "Epoch 18/25\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.3216 - accuracy: 0.9600 - val_loss: 0.3105 - val_accuracy: 0.9500\n",
      "Epoch 19/25\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.3143 - accuracy: 0.9588 - val_loss: 0.3033 - val_accuracy: 0.9500\n",
      "Epoch 20/25\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.3073 - accuracy: 0.9600 - val_loss: 0.2966 - val_accuracy: 0.9500\n",
      "Epoch 21/25\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.3007 - accuracy: 0.9638 - val_loss: 0.2900 - val_accuracy: 0.9500\n",
      "Epoch 22/25\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.2943 - accuracy: 0.9650 - val_loss: 0.2839 - val_accuracy: 0.9550\n",
      "Epoch 23/25\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.2883 - accuracy: 0.9675 - val_loss: 0.2781 - val_accuracy: 0.9600\n",
      "Epoch 24/25\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.2825 - accuracy: 0.9700 - val_loss: 0.2724 - val_accuracy: 0.9600\n",
      "Epoch 25/25\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.2770 - accuracy: 0.9712 - val_loss: 0.2669 - val_accuracy: 0.9650\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2669 - accuracy: 0.9650\n",
      "\n",
      "RNN Evaluation\n",
      "Epoch 1/30\n",
      "25/25 [==============================] - 4s 62ms/step - loss: 0.6847 - accuracy: 0.6012 - val_loss: 0.6725 - val_accuracy: 0.7200\n",
      "Epoch 2/30\n",
      "25/25 [==============================] - 1s 26ms/step - loss: 0.6562 - accuracy: 0.7412 - val_loss: 0.6241 - val_accuracy: 0.8000\n",
      "Epoch 3/30\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 0.5850 - accuracy: 0.8725 - val_loss: 0.5278 - val_accuracy: 0.9550\n",
      "Epoch 4/30\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.4815 - accuracy: 0.9550 - val_loss: 0.4324 - val_accuracy: 0.9650\n",
      "Epoch 5/30\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.4303 - accuracy: 0.9388 - val_loss: 0.3604 - val_accuracy: 0.9700\n",
      "Epoch 6/30\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.4120 - accuracy: 0.9062 - val_loss: 0.3092 - val_accuracy: 0.9700\n",
      "Epoch 7/30\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.2956 - accuracy: 0.9650 - val_loss: 0.2579 - val_accuracy: 0.9750\n",
      "Epoch 8/30\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.2521 - accuracy: 0.9650 - val_loss: 0.2153 - val_accuracy: 0.9750\n",
      "Epoch 9/30\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.2147 - accuracy: 0.9663 - val_loss: 0.1823 - val_accuracy: 0.9750\n",
      "Epoch 10/30\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.1884 - accuracy: 0.9663 - val_loss: 0.1714 - val_accuracy: 0.9700\n",
      "Epoch 11/30\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.1702 - accuracy: 0.9663 - val_loss: 0.1575 - val_accuracy: 0.9700\n",
      "Epoch 12/30\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.1584 - accuracy: 0.9663 - val_loss: 0.1472 - val_accuracy: 0.9700\n",
      "Epoch 13/30\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.1548 - accuracy: 0.9650 - val_loss: 0.1173 - val_accuracy: 0.9800\n",
      "Epoch 14/30\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.1511 - accuracy: 0.9650 - val_loss: 0.1120 - val_accuracy: 0.9800\n",
      "Epoch 15/30\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.1415 - accuracy: 0.9675 - val_loss: 0.1083 - val_accuracy: 0.9800\n",
      "Epoch 16/30\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.1326 - accuracy: 0.9700 - val_loss: 0.1052 - val_accuracy: 0.9800\n",
      "Epoch 17/30\n",
      "25/25 [==============================] - 1s 26ms/step - loss: 0.1274 - accuracy: 0.9712 - val_loss: 0.1030 - val_accuracy: 0.9800\n",
      "Epoch 18/30\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.1259 - accuracy: 0.9712 - val_loss: 0.1208 - val_accuracy: 0.9750\n",
      "Epoch 19/30\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.1214 - accuracy: 0.9725 - val_loss: 0.1199 - val_accuracy: 0.9750\n",
      "Epoch 20/30\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 0.1205 - accuracy: 0.9725 - val_loss: 0.1194 - val_accuracy: 0.9750\n",
      "Epoch 21/30\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0979 - accuracy: 0.9800 - val_loss: 0.0887 - val_accuracy: 0.9850\n",
      "Epoch 22/30\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.0981 - accuracy: 0.9800 - val_loss: 0.0871 - val_accuracy: 0.9850\n",
      "Epoch 23/30\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0973 - accuracy: 0.9800 - val_loss: 0.0861 - val_accuracy: 0.9850\n",
      "Epoch 24/30\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 0.0968 - accuracy: 0.9800 - val_loss: 0.0851 - val_accuracy: 0.9850\n",
      "Epoch 25/30\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.0964 - accuracy: 0.9800 - val_loss: 0.0841 - val_accuracy: 0.9850\n",
      "Epoch 26/30\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.0962 - accuracy: 0.9800 - val_loss: 0.0842 - val_accuracy: 0.9850\n",
      "Epoch 27/30\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 0.0961 - accuracy: 0.9800 - val_loss: 0.0834 - val_accuracy: 0.9850\n",
      "Epoch 28/30\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.0960 - accuracy: 0.9800 - val_loss: 0.0834 - val_accuracy: 0.9850\n",
      "Epoch 29/30\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 0.0958 - accuracy: 0.9800 - val_loss: 0.0831 - val_accuracy: 0.9850\n",
      "Epoch 30/30\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.0959 - accuracy: 0.9800 - val_loss: 0.0832 - val_accuracy: 0.9850\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0832 - accuracy: 0.9850\n",
      "\n",
      "TDNN - Val Loss: 0.2669312357902527, Val Accuracy: 0.9649999737739563\n",
      "RNN - Val Loss: 0.08323581516742706, Val Accuracy: 0.9850000143051147\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train and evaluate the models\n",
    "print(\"TDNN Evaluation\")\n",
    "# model_tdnn.fit(x_train, y_train, epochs=25, batch_size=32, validation_data=(x_val, y_val), callbacks=[early_stopping])\n",
    "model_tdnn.fit(x_train, y_train, epochs=25, batch_size=32, validation_data=(x_val, y_val))\n",
    "tdnn_loss, tdnn_accuracy = model_tdnn.evaluate(x_val, y_val)\n",
    "print(\"\\nRNN Evaluation\")\n",
    "# model_rnn.fit(x_train, y_train, epochs=30, batch_size=32, validation_data=(x_val, y_val), callbacks=[early_stopping])\n",
    "model_rnn.fit(x_train, y_train, epochs=30, batch_size=32, validation_data=(x_val, y_val))\n",
    "rnn_loss, rnn_accuracy = model_rnn.evaluate(x_val, y_val)\n",
    "\n",
    "print(f\"\\nTDNN - Val Loss: {tdnn_loss}, Val Accuracy: {tdnn_accuracy}\")\n",
    "print(f\"RNN - Val Loss: {rnn_loss}, Val Accuracy: {rnn_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec56cb31-ba8c-4013-b02a-ef22b345b108",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "347e40d7-4af0-4b44-b1d5-4f8275f72ad8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the data from the text file\n",
    "data = np.loadtxt('test.txt', dtype=str)\n",
    "\n",
    "new_data = []\n",
    "labels = []\n",
    "for line in data:\n",
    "    line = line.replace(\",\", \"\")  # Remove commas\n",
    "    data = line[:-1] # Drop the last element in each line\n",
    "    label = line[-1] # Last element is class label\n",
    "    new_data.append(data)\n",
    "    labels.append(label)\n",
    "\n",
    "# print(len(new_data))\n",
    "# print(len(labels[0]))\n",
    "# type(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "427e2df3-aeef-466a-aeda-d85d24c88838",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a function to one-hot encode a string\n",
    "def one_hot_encode(string, num_classes):\n",
    "    return tf.keras.utils.to_categorical([int(c) for c in string], num_classes=num_classes)\n",
    "\n",
    "num_classes = 2  # 0 or 1\n",
    "\n",
    "# One-hot encode the strings\n",
    "encoded_new_data = np.array([one_hot_encode(s, num_classes) for s in new_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d22a9400-a905-45b9-b03a-3795c05eebb2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3710 - accuracy: 0.9500\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3548 - accuracy: 0.8800\n",
      "With Evaluate Method\n",
      "---------------------------------------------------------------\n",
      "TDNN - Test Loss: 0.3709591031074524, Test Accuracy: 0.949999988079071\n",
      "RNN - Test Loss: 0.35484007000923157, Test Accuracy: 0.8799999952316284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ensure that labels are integers (0 or 1) and convert them to NumPy arrays\n",
    "y_test = np.array([int(label) for label in labels])\n",
    "\n",
    "# Evaluate the models on the test data\n",
    "tdnn_loss, tdnn_accuracy = model_tdnn.evaluate(encoded_new_data, y_test)\n",
    "rnn_loss, rnn_accuracy = model_rnn.evaluate(encoded_new_data, y_test)\n",
    "\n",
    "print(\"With Evaluate Method\")\n",
    "print(\"---------------------------------------------------------------\")\n",
    "print(f\"TDNN - Test Loss: {tdnn_loss}, Test Accuracy: {tdnn_accuracy}\")\n",
    "print(f\"RNN - Test Loss: {rnn_loss}, Test Accuracy: {rnn_accuracy}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7aff066-673b-4cd2-8ae5-dfd43c19720a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 1s 13ms/step\n",
      "TDNN Accuracy: 0.95\n",
      "RNN Accuracy: 0.88\n",
      "TDNN Confusion Matrix:\n",
      "[[225  25]\n",
      " [  0 250]]\n",
      "\n",
      "RNN Confusion Matrix:\n",
      "[[211  39]\n",
      " [ 21 229]]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "tdnn_predictions = model_tdnn.predict(encoded_new_data)\n",
    "rnn_predictions = model_rnn.predict(encoded_new_data)\n",
    "\n",
    "# Convert model outputs to binary predictions\n",
    "threshold = 0.5  # Adjust the threshold as needed\n",
    "tdnn_binary_predictions = (tdnn_predictions > threshold).astype(int)\n",
    "rnn_binary_predictions = (rnn_predictions > threshold).astype(int)\n",
    "\n",
    "# Calculate confusion matrices\n",
    "tdnn_confusion_matrix = confusion_matrix(y_test, tdnn_binary_predictions)\n",
    "rnn_confusion_matrix = confusion_matrix(y_test, rnn_binary_predictions)\n",
    "\n",
    "print(\"TDNN Accuracy:\", accuracy_score(y_test, tdnn_binary_predictions))\n",
    "print(\"RNN Accuracy:\", accuracy_score(y_test, rnn_binary_predictions))\n",
    "# Display the confusion matrices\n",
    "print(\"TDNN Confusion Matrix:\")\n",
    "print(tdnn_confusion_matrix)\n",
    "\n",
    "print(\"\\nRNN Confusion Matrix:\")\n",
    "print(rnn_confusion_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
